# syntax = docker/dockerfile:1.4
FROM nvidia/cuda:12.2.0-devel-bookworm

ARG CPU_GPU
WORKDIR /root

# 1. System & build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
      build-essential \
      cmake \
      ninja-build \
      python3-dev \
      wget \
      curl \
      git \
      python3 \
      python3-venv \
      python3-pip \
      nodejs \
 && rm -rf /var/lib/apt/lists/*

# 2. Verify CUDA compiler is present
RUN nvcc --version

# 3. Export CUDA paths for both build and runtime
ENV CUDA_HOME=/usr/local/cuda-12.2
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}
RUN ln -sfn /usr/local/cuda-12.2 /usr/local/cuda

# 4. Install GPU-enabled PyTorch (cu122)
RUN pip3 install --no-cache-dir \
      torch torchvision torchaudio \
      --extra-index-url https://download.pytorch.org/whl/cu122

# 5. Build FlashAttention during image build
RUN pip3 install --no-cache-dir flash-attn --no-build-isolation

# 6. Node.js & Yarn setup
ADD https://deb.nodesource.com/setup_23.x nodesource_setup.sh
RUN chmod +x nodesource_setup.sh && ./nodesource_setup.sh \
 && apt-get update && apt-get install -y --no-install-recommends nodejs \
 && npm install --global yarn \
 && rm -rf /var/lib/apt/lists/* nodesource_setup.sh

WORKDIR /root/modal-login
ENV YARN_CACHE_FOLDER=/root/.yarn
RUN yarn config set cache-folder $YARN_CACHE_FOLDER
COPY modal-login/package.json modal-login/package-lock.json ./
RUN --mount=type=cache,target=$YARN_CACHE_FOLDER yarn install

# 7. Python requirements for CPU path (if ever needed)
WORKDIR /root
COPY requirements-cpu.txt requirements-gpu.txt ./
RUN if [ "$CPU_GPU" = "cpu" ]; then \
      pip3 install --no-cache-dir -r requirements-cpu.txt; \
    fi

# 8. Cloudflared & entrypoint
ADD https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 /usr/local/bin/cloudflared
RUN chmod +x /usr/local/bin/cloudflared

COPY . .
RUN chmod +x ./entrypoint.sh
ENTRYPOINT [ "/root/entrypoint.sh" ]
